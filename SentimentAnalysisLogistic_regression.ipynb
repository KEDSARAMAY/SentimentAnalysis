{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisLogistic_regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlsZpQPvil24",
        "colab_type": "text"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLHyK-1niR2O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emvmjPnYCmoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "c2d6be0b-1c5b-4594-9810-eefb638bc399"
      },
      "source": [
        "!pip install contractions\n",
        "import pandas as pd\n",
        "import contractions\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import nltk.tokenize as nt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 25.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 11.1MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 26.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 33.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 36.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 24.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 26.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 30.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 29.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 23.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81696 sha256=eb984ed0131627848ffd46b065ba08f9c1a8f00a660e58334df898089e4cf38b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmW2M-XkNu1M",
        "colab_type": "text"
      },
      "source": [
        "#Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5hZ07z4NjM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "19c576be-70e9-4291-e537-5752f7f3b163"
      },
      "source": [
        "!gdown --id 1TvPCXiMeBnvsqdUYUzBhzHqok_W5JQwr"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TvPCXiMeBnvsqdUYUzBhzHqok_W5JQwr\n",
            "To: /content/lab4_train.csv\n",
            "\r  0% 0.00/331k [00:00<?, ?B/s]\r100% 331k/331k [00:00<00:00, 49.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2X_UakmTREf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('lab4_train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RCum8aPFDKbl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "bb2d4950-9f3b-4976-a754-52b6677b1eef"
      },
      "source": [
        "def tokenize_filter(string_text):\n",
        "  filter_words = []\n",
        "  contracts = contractions.fix(string_text) #เปลี่ยนคำย่อ สมมติว่า didn't เป็น did not \n",
        "  ss=nt.sent_tokenize(contracts)\n",
        "  tokenized_sent=[nt.word_tokenize(sent) for sent in ss]\n",
        "  pos_sentences=[nltk.pos_tag(sent) for sent in tokenized_sent]\n",
        "  for lst in pos_sentences:\n",
        "    for tup in lst:\n",
        "      if tup[1].startswith(('J','N','R')) and tup[0]:\n",
        "        filter_words.append(tup[0])\n",
        "  return filter_words\n",
        "\n",
        "def contract(string_text):\n",
        "  contracts = contractions.fix(string_text)\n",
        "  return contracts.split()\n",
        "\n",
        "data['tokens'] = data['text'].apply(contract)\n",
        "data['tokens']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           [But, the, staff, was, so, horrible, to, us.]\n",
              "1       [To, be, completely, fair,, the, only, redeemi...\n",
              "2       [To, be, completely, fair,, the, only, redeemi...\n",
              "3       [The, food, is, uniformly, exceptional,, with,...\n",
              "4       [Where, Gabriela, personaly, greets, you, and,...\n",
              "                              ...                        \n",
              "3151    [I, would, highly, recommend, this, place, to,...\n",
              "3152                       [The, service, is, fantastic.]\n",
              "3153    [I, recommend, that, you, try, this, hidden, s...\n",
              "3154    [The, garlic, mashed, potatoes, are, hands, do...\n",
              "3155                     [Food, and, service, was, okay.]\n",
              "Name: tokens, Length: 3156, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIVmxSrYJqMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "568fef89-6084-4909-fe51-5a328e968b94"
      },
      "source": [
        "data['aspectCategory'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "food                       1051\n",
              "anecdotes/miscellaneous     956\n",
              "service                     506\n",
              "ambience                    368\n",
              "price                       275\n",
              "Name: aspectCategory, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIyRWdI9J9Ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "2b84e832-77bb-47e8-9581-8eafc1a2a1c7"
      },
      "source": [
        "data ['polarity'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    1876\n",
              "negative     715\n",
              "neutral      398\n",
              "conflict     167\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn1VoUwjEC-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "15a926b9-cf8a-42db-bef2-96a1304bd956"
      },
      "source": [
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>aspectCategory</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3121</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>service</td>\n",
              "      <td>negative</td>\n",
              "      <td>[But, the, staff, was, so, horrible, to, us.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>[To, be, completely, fair,, the, only, redeemi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2777</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "      <td>negative</td>\n",
              "      <td>[To, be, completely, fair,, the, only, redeemi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1634</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>[The, food, is, uniformly, exceptional,, with,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2534</td>\n",
              "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
              "      <td>service</td>\n",
              "      <td>positive</td>\n",
              "      <td>[Where, Gabriela, personaly, greets, you, and,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3151</th>\n",
              "      <td>2853</td>\n",
              "      <td>I would highly recommend this place to everyon...</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "      <td>positive</td>\n",
              "      <td>[I, would, highly, recommend, this, place, to,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3152</th>\n",
              "      <td>1163</td>\n",
              "      <td>The service is fantastic.</td>\n",
              "      <td>service</td>\n",
              "      <td>positive</td>\n",
              "      <td>[The, service, is, fantastic.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3153</th>\n",
              "      <td>216</td>\n",
              "      <td>I recommend that you try this hidden spot whic...</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "      <td>positive</td>\n",
              "      <td>[I, recommend, that, you, try, this, hidden, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3154</th>\n",
              "      <td>1109</td>\n",
              "      <td>The garlic mashed potatoes are hands down the ...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "      <td>[The, garlic, mashed, potatoes, are, hands, do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3155</th>\n",
              "      <td>899</td>\n",
              "      <td>Food and service was okay.</td>\n",
              "      <td>food</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[Food, and, service, was, okay.]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3156 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                             tokens\n",
              "0     3121  ...      [But, the, staff, was, so, horrible, to, us.]\n",
              "1     2777  ...  [To, be, completely, fair,, the, only, redeemi...\n",
              "2     2777  ...  [To, be, completely, fair,, the, only, redeemi...\n",
              "3     1634  ...  [The, food, is, uniformly, exceptional,, with,...\n",
              "4     2534  ...  [Where, Gabriela, personaly, greets, you, and,...\n",
              "...    ...  ...                                                ...\n",
              "3151  2853  ...  [I, would, highly, recommend, this, place, to,...\n",
              "3152  1163  ...                     [The, service, is, fantastic.]\n",
              "3153   216  ...  [I, recommend, that, you, try, this, hidden, s...\n",
              "3154  1109  ...  [The, garlic, mashed, potatoes, are, hands, do...\n",
              "3155   899  ...                   [Food, and, service, was, okay.]\n",
              "\n",
              "[3156 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr1qJ6ZgFH7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6d3498f9-f860-4907-9509-735a280c97e1"
      },
      "source": [
        "data['tokens'][700]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Others',\n",
              " 'have',\n",
              " 'to',\n",
              " 'go',\n",
              " 'to',\n",
              " 'other',\n",
              " 'restaurants',\n",
              " 'and',\n",
              " 'feel',\n",
              " 'sad',\n",
              " 'until',\n",
              " 'they',\n",
              " 'are',\n",
              " 'eaten.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2GyDyVEWyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, dev = np.split(data, [int(0.8 * len(data))])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjN-2aZSieEn",
        "colab_type": "text"
      },
      "source": [
        "#Featurize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HSe6iVAG3Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def featurize(token_list):\n",
        "    dic = {}\n",
        "    for i in range(len(token_list)):\n",
        "        dic[token_list[i]] = 1\n",
        "    return dic\n",
        "\n",
        "def unibi_gram(token_list):\n",
        "  unibi_dic = {}\n",
        "  for i in range(len(token_list)-1):\n",
        "    unibi_dic[token_list[i]] = 1\n",
        "    unibi_dic[token_list[i] + '_' +token_list[i+1]] = 1\n",
        "  return unibi_dic"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlB9qvaJHOWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_dict_list = [unibi_gram(x) for x in train['tokens']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y7CccIfHQro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "8b2bf8a7-535b-4d8e-9e8b-4d8b7dc5c968"
      },
      "source": [
        "feature_dict_list[1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'To': 1,\n",
              " 'To_be': 1,\n",
              " 'above': 1,\n",
              " 'above_average,': 1,\n",
              " 'all': 1,\n",
              " 'all_the': 1,\n",
              " 'average,': 1,\n",
              " 'average,_but': 1,\n",
              " 'be': 1,\n",
              " 'be_completely': 1,\n",
              " 'but': 1,\n",
              " 'but_could': 1,\n",
              " 'completely': 1,\n",
              " 'completely_fair,': 1,\n",
              " 'could': 1,\n",
              " 'could_not': 1,\n",
              " 'deficiencies': 1,\n",
              " 'deficiencies_of': 1,\n",
              " 'factor': 1,\n",
              " 'factor_was': 1,\n",
              " 'fair,': 1,\n",
              " 'fair,_the': 1,\n",
              " 'food,': 1,\n",
              " 'food,_which': 1,\n",
              " 'for': 1,\n",
              " 'for_all': 1,\n",
              " 'make': 1,\n",
              " 'make_up': 1,\n",
              " 'not': 1,\n",
              " 'not_make': 1,\n",
              " 'of': 1,\n",
              " 'of_Teodora.': 1,\n",
              " 'only': 1,\n",
              " 'only_redeeming': 1,\n",
              " 'other': 1,\n",
              " 'other_deficiencies': 1,\n",
              " 'redeeming': 1,\n",
              " 'redeeming_factor': 1,\n",
              " 'the': 1,\n",
              " 'the_food,': 1,\n",
              " 'the_only': 1,\n",
              " 'the_other': 1,\n",
              " 'up': 1,\n",
              " 'up_for': 1,\n",
              " 'was': 1,\n",
              " 'was_above': 1,\n",
              " 'was_the': 1,\n",
              " 'which': 1,\n",
              " 'which_was': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9339Qj_miHPb",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f52PV06zHi1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "557c6f7a-ab1b-45e5-bcd0-02633e36160d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "vectorizer = DictVectorizer(sparse=True)\n",
        "train_features = train['tokens'].apply(featurize)\n",
        "feature_vectors = vectorizer.fit_transform(train_features) \n",
        "\n",
        "lr_text_classifier = LogisticRegression()\n",
        "lr_text_classifier.fit(feature_vectors, train['polarity']) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMBT9QdINk3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "016d11a7-5725-4eb7-9a7f-9b2cb0834eb9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
        "dev_featurized_list_dicts = dev['tokens'].apply(featurize)\n",
        "dev_feature_vector = vectorizer.transform(dev_featurized_list_dicts) \n",
        "dev_feature_vector"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<632x5686 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7659 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AZ8LCOENzio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a4599746-052e-4619-907a-327a4db667aa"
      },
      "source": [
        "polarity_predictions = lr_text_classifier.predict(dev_feature_vector)\n",
        "print (classification_report(dev['polarity'], polarity_predictions))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    conflict       0.26      0.36      0.30        25\n",
            "    negative       0.51      0.27      0.35       150\n",
            "     neutral       0.47      0.21      0.29        77\n",
            "    positive       0.70      0.89      0.79       380\n",
            "\n",
            "    accuracy                           0.64       632\n",
            "   macro avg       0.48      0.43      0.43       632\n",
            "weighted avg       0.61      0.64      0.60       632\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WczADxXZT-8L"
      },
      "source": [
        "#Aspect analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhxGZGyTQEJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5e2463ee-8d4b-4a52-e191-dbc3df2381af"
      },
      "source": [
        "lr_text_classifier = LogisticRegression()\n",
        "lr_text_classifier.fit(feature_vectors, train['aspectCategory']) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJqC4kkjUKL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2d9a33a0-59db-4cdb-f5bf-d550535cd7a2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
        "dev_featurized_list_dicts = dev['tokens'].apply(featurize)\n",
        "dev_feature_vector = vectorizer.transform(dev_featurized_list_dicts) \n",
        "dev_feature_vector"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<632x5686 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7659 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GslJ5cYEUORZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "93b17e8e-931f-4cfb-aaa5-0972afcbc528"
      },
      "source": [
        "aspect_predictions = lr_text_classifier.predict(dev_feature_vector)\n",
        "print (classification_report(dev['aspectCategory'], aspect_predictions))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "               ambience       0.54      0.28      0.37        71\n",
            "anecdotes/miscellaneous       0.68      0.79      0.73       194\n",
            "                   food       0.62      0.78      0.69       203\n",
            "                  price       0.42      0.13      0.20        60\n",
            "                service       0.62      0.56      0.59       104\n",
            "\n",
            "               accuracy                           0.63       632\n",
            "              macro avg       0.58      0.51      0.52       632\n",
            "           weighted avg       0.61      0.63      0.60       632\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isz4ehFTbjYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b7559a7c-4d69-4e1a-e2b0-c44b77f87eea"
      },
      "source": [
        "file = pd.DataFrame()\n",
        "file['id'] = dev['id']\n",
        "file['polarity'] = polarity_predictions\n",
        "file['aspectCategory'] = aspect_predictions\n",
        "file.to_csv('pred.csv', index=None)\n",
        "file"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>aspectCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2524</th>\n",
              "      <td>3235</td>\n",
              "      <td>positive</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2525</th>\n",
              "      <td>3480</td>\n",
              "      <td>neutral</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>1459</td>\n",
              "      <td>neutral</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2527</th>\n",
              "      <td>1459</td>\n",
              "      <td>neutral</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2528</th>\n",
              "      <td>1597</td>\n",
              "      <td>positive</td>\n",
              "      <td>price</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3151</th>\n",
              "      <td>2853</td>\n",
              "      <td>positive</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3152</th>\n",
              "      <td>1163</td>\n",
              "      <td>positive</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3153</th>\n",
              "      <td>216</td>\n",
              "      <td>positive</td>\n",
              "      <td>anecdotes/miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3154</th>\n",
              "      <td>1109</td>\n",
              "      <td>positive</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3155</th>\n",
              "      <td>899</td>\n",
              "      <td>positive</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>632 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  polarity           aspectCategory\n",
              "2524  3235  positive                  service\n",
              "2525  3480   neutral  anecdotes/miscellaneous\n",
              "2526  1459   neutral                     food\n",
              "2527  1459   neutral                     food\n",
              "2528  1597  positive                    price\n",
              "...    ...       ...                      ...\n",
              "3151  2853  positive  anecdotes/miscellaneous\n",
              "3152  1163  positive                  service\n",
              "3153   216  positive  anecdotes/miscellaneous\n",
              "3154  1109  positive                     food\n",
              "3155   899  positive                  service\n",
              "\n",
              "[632 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGbY6zwNgLPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "dcb3a0bc-7783-46d8-ac8f-666ee8f1be33"
      },
      "source": [
        "!gdown --id 1YtAHCzeZUXGZQ9cimdkkUq4lUk3ZH-I_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YtAHCzeZUXGZQ9cimdkkUq4lUk3ZH-I_\n",
            "To: /content/evaluate.py\n",
            "\r  0% 0.00/7.03k [00:00<?, ?B/s]\r100% 7.03k/7.03k [00:00<00:00, 14.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zimzMxhf3ap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "28995f07-3cca-4cd6-adb3-f53e31833d17"
      },
      "source": [
        "!python3 evaluate.py lab4_train.csv pred.csv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== CLASSIFICATION : ASPECT ===\n",
            "                class name  precision  recall  F1-score support\n",
            "0                     food      0.849   0.778     0.812     203\n",
            "1                    price      0.727   0.133     0.225      60\n",
            "2                  service      0.866   0.558     0.678     104\n",
            "3                 ambience      0.769   0.282     0.412      71\n",
            "4  anecdotes/miscellaneous      0.744   0.794     0.768     194\n",
            "5                MACRO AVG      0.791   0.509     0.579     632\n",
            "6                MICRO AVG      0.801   0.630     0.705     632 \n",
            "\n",
            "=== CLASSIFICATION : SENTIMENT ===\n",
            "  class name  precision  recall  F1-score support\n",
            "0   positive      0.720   0.892     0.797     306\n",
            "1   negative      0.522   0.280     0.365     125\n",
            "2    neutral      0.533   0.216     0.308      74\n",
            "3   conflict      0.429   0.375     0.400      24\n",
            "4  MACRO AVG      0.551   0.441     0.467     529\n",
            "5  MICRO AVG      0.670   0.629     0.649     529 \n",
            "\n",
            "=== CLASSIFICATION : OVERALL ===\n",
            "              precision  recall  F1-score support\n",
            "0  MICRO AVG      0.537   0.422     0.473     632 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}